{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Segmentation using Clustering\n",
    "***\n",
    "This mini-project is based on [this blog post](http://blog.yhat.com/posts/customer-segmentation-using-python.html) by yhat. Please feel free to refer to the post for additional information, and solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Setup Seaborn\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The dataset contains information on marketing newsletters/e-mail campaigns (e-mail offers sent to customers) and transaction level data from customers. The transactional data shows which offer customers responded to, and what the customer ended up buying. The data is presented as an Excel workbook containing two worksheets. Each worksheet contains a different dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\preethim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\util\\_decorators.py:188: FutureWarning:\n",
      "\n",
      "The `sheetname` keyword is deprecated, use `sheet_name` instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offer_id</th>\n",
       "      <th>campaign</th>\n",
       "      <th>varietal</th>\n",
       "      <th>min_qty</th>\n",
       "      <th>discount</th>\n",
       "      <th>origin</th>\n",
       "      <th>past_peak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>Malbec</td>\n",
       "      <td>72</td>\n",
       "      <td>56</td>\n",
       "      <td>France</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>January</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>72</td>\n",
       "      <td>17</td>\n",
       "      <td>France</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>February</td>\n",
       "      <td>Espumante</td>\n",
       "      <td>144</td>\n",
       "      <td>32</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>February</td>\n",
       "      <td>Champagne</td>\n",
       "      <td>72</td>\n",
       "      <td>48</td>\n",
       "      <td>France</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>February</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>144</td>\n",
       "      <td>44</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offer_id  campaign            varietal  min_qty  discount       origin  \\\n",
       "0         1   January              Malbec       72        56       France   \n",
       "1         2   January          Pinot Noir       72        17       France   \n",
       "2         3  February           Espumante      144        32       Oregon   \n",
       "3         4  February           Champagne       72        48       France   \n",
       "4         5  February  Cabernet Sauvignon      144        44  New Zealand   \n",
       "\n",
       "   past_peak  \n",
       "0      False  \n",
       "1      False  \n",
       "2       True  \n",
       "3       True  \n",
       "4       True  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_offers = pd.read_excel(\"./WineKMC.xlsx\", sheetname=0)\n",
    "df_offers.columns = [\"offer_id\", \"campaign\", \"varietal\", \"min_qty\", \"discount\", \"origin\", \"past_peak\"]\n",
    "df_offers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the first dataset contains information about each offer such as the month it is in effect and several attributes about the wine that the offer refers to: the variety, minimum quantity, discount, country of origin and whether or not it is past peak. The second dataset in the second worksheet contains transactional data -- which offer each customer responded to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_name</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Smith</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Smith</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Johnson</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Johnson</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Johnson</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Williams</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Williams</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Williams</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Brown</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Brown</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Brown</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Jones</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Miller</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Miller</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Miller</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Miller</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Miller</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Miller</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Miller</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Davis</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Davis</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Davis</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Garcia</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Garcia</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Rodriguez</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Rodriguez</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Wilson</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Wilson</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Martinez</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Martinez</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Sullivan</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Sullivan</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Russell</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Ortiz</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Jenkins</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Jenkins</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Gutierrez</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Gutierrez</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Gutierrez</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Gutierrez</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Perry</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Perry</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Perry</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Perry</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Butler</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Butler</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>Butler</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>Butler</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>Butler</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>Barnes</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Barnes</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Barnes</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Barnes</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Fisher</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>Fisher</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>Fisher</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>Fisher</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>Fisher</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>Fisher</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>Fisher</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    customer_name  offer_id  n\n",
       "0           Smith         2  1\n",
       "1           Smith        24  1\n",
       "2         Johnson        17  1\n",
       "3         Johnson        24  1\n",
       "4         Johnson        26  1\n",
       "5        Williams        18  1\n",
       "6        Williams        22  1\n",
       "7        Williams        31  1\n",
       "8           Brown         7  1\n",
       "9           Brown        29  1\n",
       "10          Brown        30  1\n",
       "11          Jones         8  1\n",
       "12         Miller         6  1\n",
       "13         Miller        10  1\n",
       "14         Miller        14  1\n",
       "15         Miller        15  1\n",
       "16         Miller        22  1\n",
       "17         Miller        23  1\n",
       "18         Miller        31  1\n",
       "19          Davis        12  1\n",
       "20          Davis        22  1\n",
       "21          Davis        25  1\n",
       "22         Garcia        14  1\n",
       "23         Garcia        15  1\n",
       "24      Rodriguez         2  1\n",
       "25      Rodriguez        26  1\n",
       "26         Wilson         8  1\n",
       "27         Wilson        30  1\n",
       "28       Martinez        12  1\n",
       "29       Martinez        25  1\n",
       "..            ...       ... ..\n",
       "294      Sullivan        13  1\n",
       "295      Sullivan        18  1\n",
       "296       Russell        26  1\n",
       "297         Ortiz         8  1\n",
       "298       Jenkins        24  1\n",
       "299       Jenkins        26  1\n",
       "300     Gutierrez         6  1\n",
       "301     Gutierrez         8  1\n",
       "302     Gutierrez        10  1\n",
       "303     Gutierrez        18  1\n",
       "304         Perry         8  1\n",
       "305         Perry        18  1\n",
       "306         Perry        29  1\n",
       "307         Perry        30  1\n",
       "308        Butler         1  1\n",
       "309        Butler         4  1\n",
       "310        Butler        22  1\n",
       "311        Butler        28  1\n",
       "312        Butler        30  1\n",
       "313        Barnes        10  1\n",
       "314        Barnes        21  1\n",
       "315        Barnes        22  1\n",
       "316        Barnes        31  1\n",
       "317        Fisher         1  1\n",
       "318        Fisher         2  1\n",
       "319        Fisher        11  1\n",
       "320        Fisher        22  1\n",
       "321        Fisher        28  1\n",
       "322        Fisher        30  1\n",
       "323        Fisher        31  1\n",
       "\n",
       "[324 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions = pd.read_excel(\"./WineKMC.xlsx\", sheetname=1)\n",
    "df_transactions.columns = [\"customer_name\", \"offer_id\"]\n",
    "df_transactions['n'] = 1\n",
    "#df_transactions = df_transactions[df_transactions.n>1]\n",
    "df_transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're trying to learn more about how our customers behave, so we can use their behavior (whether or not they purchased something based on an offer) as a way to group similar minded customers together. We can then study those groups to look for patterns and trends which can help us formulate future offers.\n",
    "\n",
    "The first thing we need is a way to compare customers. To do this, we're going to create a matrix that contains each customer and a 0/1 indicator for whether or not they responded to a given offer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<h3>Checkup Exercise Set I</h3>\n",
    "\n",
    "<p><b>Exercise:</b> Create a data frame where each row has the following columns (Use the pandas [`merge`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html) and [`pivot_table`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.pivot_table.html) functions for this purpose):\n",
    "<ul>\n",
    "<li> customer_name\n",
    "<li> One column for each offer, with a 1 if the customer responded to the offer\n",
    "</ul>\n",
    "<p>Make sure you also deal with any weird values such as `NaN`. Read the documentation to develop your solution.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_name</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>n</th>\n",
       "      <th>campaign</th>\n",
       "      <th>varietal</th>\n",
       "      <th>min_qty</th>\n",
       "      <th>discount</th>\n",
       "      <th>origin</th>\n",
       "      <th>past_peak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Smith</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>72</td>\n",
       "      <td>17</td>\n",
       "      <td>France</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rodriguez</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>72</td>\n",
       "      <td>17</td>\n",
       "      <td>France</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Martin</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>72</td>\n",
       "      <td>17</td>\n",
       "      <td>France</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jackson</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>72</td>\n",
       "      <td>17</td>\n",
       "      <td>France</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Campbell</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>72</td>\n",
       "      <td>17</td>\n",
       "      <td>France</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mitchell</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>72</td>\n",
       "      <td>17</td>\n",
       "      <td>France</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Peterson</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>72</td>\n",
       "      <td>17</td>\n",
       "      <td>France</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bell</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>72</td>\n",
       "      <td>17</td>\n",
       "      <td>France</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cox</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>72</td>\n",
       "      <td>17</td>\n",
       "      <td>France</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fisher</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>72</td>\n",
       "      <td>17</td>\n",
       "      <td>France</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Smith</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>September</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>Italy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Johnson</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>September</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>Italy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Anderson</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>September</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>Italy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Moore</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>September</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>Italy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Campbell</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>September</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>Italy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Phillips</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>September</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>Italy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Flores</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>September</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>Italy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Morris</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>September</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>Italy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cook</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>September</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>Italy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bell</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>September</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>Italy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Cox</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>September</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>Italy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Jenkins</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>September</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>Italy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Johnson</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>12</td>\n",
       "      <td>47</td>\n",
       "      <td>Germany</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Moore</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>12</td>\n",
       "      <td>47</td>\n",
       "      <td>Germany</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Phillips</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>12</td>\n",
       "      <td>47</td>\n",
       "      <td>Germany</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Flores</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>12</td>\n",
       "      <td>47</td>\n",
       "      <td>Germany</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Morris</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>12</td>\n",
       "      <td>47</td>\n",
       "      <td>Germany</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Bell</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>12</td>\n",
       "      <td>47</td>\n",
       "      <td>Germany</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Cox</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>12</td>\n",
       "      <td>47</td>\n",
       "      <td>Germany</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Johnson</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>October</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>144</td>\n",
       "      <td>83</td>\n",
       "      <td>Australia</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Long</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>February</td>\n",
       "      <td>Espumante</td>\n",
       "      <td>144</td>\n",
       "      <td>32</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Harris</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>Champagne</td>\n",
       "      <td>12</td>\n",
       "      <td>66</td>\n",
       "      <td>Germany</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Baker</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>Champagne</td>\n",
       "      <td>12</td>\n",
       "      <td>66</td>\n",
       "      <td>Germany</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Nguyen</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>Champagne</td>\n",
       "      <td>12</td>\n",
       "      <td>66</td>\n",
       "      <td>Germany</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Rogers</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>Champagne</td>\n",
       "      <td>12</td>\n",
       "      <td>66</td>\n",
       "      <td>Germany</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Morales</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>Champagne</td>\n",
       "      <td>12</td>\n",
       "      <td>66</td>\n",
       "      <td>Germany</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Young</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>December</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>72</td>\n",
       "      <td>45</td>\n",
       "      <td>Germany</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Cooper</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>December</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>72</td>\n",
       "      <td>45</td>\n",
       "      <td>Germany</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Gomez</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>December</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>72</td>\n",
       "      <td>45</td>\n",
       "      <td>Germany</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Kelly</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>December</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>72</td>\n",
       "      <td>45</td>\n",
       "      <td>Germany</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Sanchez</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>February</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>144</td>\n",
       "      <td>44</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Reed</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>February</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>144</td>\n",
       "      <td>44</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Sanders</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>February</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>144</td>\n",
       "      <td>44</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Powell</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>February</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>144</td>\n",
       "      <td>44</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Sanchez</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>August</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>72</td>\n",
       "      <td>82</td>\n",
       "      <td>Italy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Parker</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>August</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>72</td>\n",
       "      <td>82</td>\n",
       "      <td>Italy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>Cooper</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>August</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>72</td>\n",
       "      <td>82</td>\n",
       "      <td>Italy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>Gomez</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>August</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>72</td>\n",
       "      <td>82</td>\n",
       "      <td>Italy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>Kelly</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>August</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>72</td>\n",
       "      <td>82</td>\n",
       "      <td>Italy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>Sanders</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>August</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>72</td>\n",
       "      <td>82</td>\n",
       "      <td>Italy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Wright</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>August</td>\n",
       "      <td>Champagne</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>California</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Rogers</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>August</td>\n",
       "      <td>Champagne</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>California</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Ross</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>August</td>\n",
       "      <td>Champagne</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>California</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Barnes</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>August</td>\n",
       "      <td>Champagne</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>California</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>King</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>May</td>\n",
       "      <td>Merlot</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>Chile</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>Hill</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>May</td>\n",
       "      <td>Merlot</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>Chile</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>Carter</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>May</td>\n",
       "      <td>Merlot</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>Chile</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>James</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>May</td>\n",
       "      <td>Merlot</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>Chile</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>Hughes</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>May</td>\n",
       "      <td>Merlot</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>Chile</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>Sullivan</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>May</td>\n",
       "      <td>Merlot</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>Chile</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    customer_name  offer_id  n   campaign            varietal  min_qty  \\\n",
       "0           Smith         2  1    January          Pinot Noir       72   \n",
       "1       Rodriguez         2  1    January          Pinot Noir       72   \n",
       "2          Martin         2  1    January          Pinot Noir       72   \n",
       "3         Jackson         2  1    January          Pinot Noir       72   \n",
       "4        Campbell         2  1    January          Pinot Noir       72   \n",
       "5        Mitchell         2  1    January          Pinot Noir       72   \n",
       "6        Peterson         2  1    January          Pinot Noir       72   \n",
       "7            Bell         2  1    January          Pinot Noir       72   \n",
       "8             Cox         2  1    January          Pinot Noir       72   \n",
       "9          Fisher         2  1    January          Pinot Noir       72   \n",
       "10          Smith        24  1  September          Pinot Noir        6   \n",
       "11        Johnson        24  1  September          Pinot Noir        6   \n",
       "12       Anderson        24  1  September          Pinot Noir        6   \n",
       "13          Moore        24  1  September          Pinot Noir        6   \n",
       "14       Campbell        24  1  September          Pinot Noir        6   \n",
       "15       Phillips        24  1  September          Pinot Noir        6   \n",
       "16         Flores        24  1  September          Pinot Noir        6   \n",
       "17         Morris        24  1  September          Pinot Noir        6   \n",
       "18           Cook        24  1  September          Pinot Noir        6   \n",
       "19           Bell        24  1  September          Pinot Noir        6   \n",
       "20            Cox        24  1  September          Pinot Noir        6   \n",
       "21        Jenkins        24  1  September          Pinot Noir        6   \n",
       "22        Johnson        17  1       July          Pinot Noir       12   \n",
       "23          Moore        17  1       July          Pinot Noir       12   \n",
       "24       Phillips        17  1       July          Pinot Noir       12   \n",
       "25         Flores        17  1       July          Pinot Noir       12   \n",
       "26         Morris        17  1       July          Pinot Noir       12   \n",
       "27           Bell        17  1       July          Pinot Noir       12   \n",
       "28            Cox        17  1       July          Pinot Noir       12   \n",
       "29        Johnson        26  1    October          Pinot Noir      144   \n",
       "..            ...       ... ..        ...                 ...      ...   \n",
       "294          Long         3  1   February           Espumante      144   \n",
       "295        Harris        19  1       July           Champagne       12   \n",
       "296         Baker        19  1       July           Champagne       12   \n",
       "297        Nguyen        19  1       July           Champagne       12   \n",
       "298        Rogers        19  1       July           Champagne       12   \n",
       "299       Morales        19  1       July           Champagne       12   \n",
       "300         Young        32  1   December  Cabernet Sauvignon       72   \n",
       "301        Cooper        32  1   December  Cabernet Sauvignon       72   \n",
       "302         Gomez        32  1   December  Cabernet Sauvignon       72   \n",
       "303         Kelly        32  1   December  Cabernet Sauvignon       72   \n",
       "304       Sanchez         5  1   February  Cabernet Sauvignon      144   \n",
       "305          Reed         5  1   February  Cabernet Sauvignon      144   \n",
       "306       Sanders         5  1   February  Cabernet Sauvignon      144   \n",
       "307        Powell         5  1   February  Cabernet Sauvignon      144   \n",
       "308       Sanchez        20  1     August  Cabernet Sauvignon       72   \n",
       "309        Parker        20  1     August  Cabernet Sauvignon       72   \n",
       "310        Cooper        20  1     August  Cabernet Sauvignon       72   \n",
       "311         Gomez        20  1     August  Cabernet Sauvignon       72   \n",
       "312         Kelly        20  1     August  Cabernet Sauvignon       72   \n",
       "313       Sanders        20  1     August  Cabernet Sauvignon       72   \n",
       "314        Wright        21  1     August           Champagne       12   \n",
       "315        Rogers        21  1     August           Champagne       12   \n",
       "316          Ross        21  1     August           Champagne       12   \n",
       "317        Barnes        21  1     August           Champagne       12   \n",
       "318          King        13  1        May              Merlot        6   \n",
       "319          Hill        13  1        May              Merlot        6   \n",
       "320        Carter        13  1        May              Merlot        6   \n",
       "321         James        13  1        May              Merlot        6   \n",
       "322        Hughes        13  1        May              Merlot        6   \n",
       "323      Sullivan        13  1        May              Merlot        6   \n",
       "\n",
       "     discount       origin  past_peak  \n",
       "0          17       France      False  \n",
       "1          17       France      False  \n",
       "2          17       France      False  \n",
       "3          17       France      False  \n",
       "4          17       France      False  \n",
       "5          17       France      False  \n",
       "6          17       France      False  \n",
       "7          17       France      False  \n",
       "8          17       France      False  \n",
       "9          17       France      False  \n",
       "10         34        Italy      False  \n",
       "11         34        Italy      False  \n",
       "12         34        Italy      False  \n",
       "13         34        Italy      False  \n",
       "14         34        Italy      False  \n",
       "15         34        Italy      False  \n",
       "16         34        Italy      False  \n",
       "17         34        Italy      False  \n",
       "18         34        Italy      False  \n",
       "19         34        Italy      False  \n",
       "20         34        Italy      False  \n",
       "21         34        Italy      False  \n",
       "22         47      Germany      False  \n",
       "23         47      Germany      False  \n",
       "24         47      Germany      False  \n",
       "25         47      Germany      False  \n",
       "26         47      Germany      False  \n",
       "27         47      Germany      False  \n",
       "28         47      Germany      False  \n",
       "29         83    Australia      False  \n",
       "..        ...          ...        ...  \n",
       "294        32       Oregon       True  \n",
       "295        66      Germany      False  \n",
       "296        66      Germany      False  \n",
       "297        66      Germany      False  \n",
       "298        66      Germany      False  \n",
       "299        66      Germany      False  \n",
       "300        45      Germany       True  \n",
       "301        45      Germany       True  \n",
       "302        45      Germany       True  \n",
       "303        45      Germany       True  \n",
       "304        44  New Zealand       True  \n",
       "305        44  New Zealand       True  \n",
       "306        44  New Zealand       True  \n",
       "307        44  New Zealand       True  \n",
       "308        82        Italy      False  \n",
       "309        82        Italy      False  \n",
       "310        82        Italy      False  \n",
       "311        82        Italy      False  \n",
       "312        82        Italy      False  \n",
       "313        82        Italy      False  \n",
       "314        50   California      False  \n",
       "315        50   California      False  \n",
       "316        50   California      False  \n",
       "317        50   California      False  \n",
       "318        43        Chile      False  \n",
       "319        43        Chile      False  \n",
       "320        43        Chile      False  \n",
       "321        43        Chile      False  \n",
       "322        43        Chile      False  \n",
       "323        43        Chile      False  \n",
       "\n",
       "[324 rows x 9 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your turn\n",
    "import numpy as np\n",
    "df = df_transactions.merge(df_offers,left_on='offer_id',right_on='offer_id')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>varietal</th>\n",
       "      <th>Cabernet Sauvignon</th>\n",
       "      <th>Champagne</th>\n",
       "      <th>Chardonnay</th>\n",
       "      <th>Espumante</th>\n",
       "      <th>Malbec</th>\n",
       "      <th>Merlot</th>\n",
       "      <th>Pinot Grigio</th>\n",
       "      <th>Pinot Noir</th>\n",
       "      <th>Prosecco</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adams</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Allen</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anderson</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bailey</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baker</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "varietal       Cabernet Sauvignon  Champagne  Chardonnay  Espumante  Malbec  \\\n",
       "customer_name                                                                 \n",
       "Adams                           0          0           0          1       1   \n",
       "Allen                           0          1           1          0       0   \n",
       "Anderson                        0          0           0          0       0   \n",
       "Bailey                          0          0           0          0       1   \n",
       "Baker                           0          1           0          0       0   \n",
       "\n",
       "varietal       Merlot  Pinot Grigio  Pinot Noir  Prosecco  \n",
       "customer_name                                              \n",
       "Adams               0             1           0         0  \n",
       "Allen               0             0           0         0  \n",
       "Anderson            0             0           1         0  \n",
       "Bailey              0             0           0         1  \n",
       "Baker               0             0           0         1  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.pivot_table(df, values='n', index=['customer_name'],columns=['varietal'], fill_value=0)\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering\n",
    "\n",
    "Recall that in K-Means Clustering we want to *maximize* the distance between centroids and *minimize* the distance between data points and the respective centroid for the cluster they are in. True evaluation for unsupervised learning would require labeled data; however, we can use a variety of intuitive metrics to try to pick the number of clusters K. We will introduce two methods: the Elbow method, the Silhouette method and the gap statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing K: The Elbow Sum-of-Squares Method\n",
    "\n",
    "The first method looks at the sum-of-squares error in each cluster against $K$. We compute the distance from each data point to the center of the cluster (centroid) to which the data point was assigned. \n",
    "\n",
    "$$SS = \\sum_k \\sum_{x_i \\in C_k} \\sum_{x_j \\in C_k} \\left( x_i - x_j \\right)^2 = \\sum_k \\sum_{x_i \\in C_k} \\left( x_i - \\mu_k \\right)^2$$\n",
    "\n",
    "where $x_i$ is a point, $C_k$ represents cluster $k$ and $\\mu_k$ is the centroid for cluster $k$. We can plot SS vs. $K$ and choose the *elbow point* in the plot as the best value for $K$. The elbow point is the point at which the plot starts descending much more slowly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<h3>Checkup Exercise Set II</h3>\n",
    "\n",
    "<p><b>Exercise:</b></p> \n",
    "<ul>\n",
    "<li> What values of $SS$ do you believe represent better clusterings? Why?\n",
    "<li> Create a numpy matrix `x_cols` with only the columns representing the offers (i.e. the 0/1 colums) \n",
    "<li> Write code that applies the [`KMeans`](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) clustering method from scikit-learn to this matrix. \n",
    "<li> Construct a plot showing $SS$ for each $K$ and pick $K$ using this plot. For simplicity, test $2 \\le K \\le 10$.\n",
    "<li> Make a bar chart showing the number of points in each cluster for k-means under the best $K$.\n",
    "<li> What challenges did you experience using the Elbow method to pick $K$?\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 0 0 1 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 1 0 0]\n",
      " [0 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 0 1]\n",
      " [1 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 0 0 1 1 1 0 1]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [1 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 0 0 1 0 1 0 0]\n",
      " [1 0 0 0 0 0 0 1]\n",
      " [0 0 1 1 0 1 0 1]\n",
      " [0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [1 0 0 1 0 0 1 0]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 1 0 1 1 0 0 0]\n",
      " [1 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 1 1]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 1 0 0]\n",
      " [0 0 1 1 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [0 0 1 1 1 1 0 1]\n",
      " [1 0 0 1 0 0 1 0]\n",
      " [0 0 1 1 1 0 0 1]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 1]\n",
      " [0 0 1 0 1 1 0 1]\n",
      " [0 0 1 0 0 0 0 1]\n",
      " [0 0 1 1 0 0 0 1]\n",
      " [0 0 1 0 0 0 0 1]\n",
      " [1 1 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 1 0]\n",
      " [1 0 0 0 0 0 0 1]\n",
      " [1 1 0 0 1 0 0 1]\n",
      " [0 0 0 1 0 0 1 0]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 1]\n",
      " [0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0]\n",
      " [1 0 0 0 1 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 1 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 1 1]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [1 0 0 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 1]\n",
      " [0 0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 1]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 1]\n",
      " [0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [1 0 0 0 1 0 1 0]\n",
      " [1 1 0 1 0 0 1 1]\n",
      " [0 1 0 0 1 0 0 1]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 0 1 1 0 1 0 0]\n",
      " [0 0 1 0 1 0 0 0]\n",
      " [0 0 1 1 0 1 0 1]\n",
      " [0 1 0 1 1 0 1 0]\n",
      " [1 1 0 1 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 1]\n",
      " [1 0 0 1 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 1 1 0 0 1]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [1 1 0 0 0 0 0 1]]\n",
      "[112.73980664144597, 96.56417806484296, 83.89245841877421, 74.36314102564103, 67.48543523469993, 60.65416666666667, 53.36237524552742, 49.33772326744463]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "x_cols = np.array(table)\n",
    "x_cols = np.delete(x_cols, np.s_[1:2], axis=1)  \n",
    "print(x_cols)\n",
    "SS = []\n",
    "K = range(2,10)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(x_cols)\n",
    "    SS.append(km.inertia_)\n",
    "print(SS)\n",
    "plt.plot(K, SS, 'bx-')\n",
    "plt.xlabel('No of Clusters')\n",
    "plt.ylabel('SS')\n",
    "plt.title('')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Choosing K: The Silhouette Method\n",
    "\n",
    "There exists another method that measures how well each datapoint $x_i$ \"fits\" its assigned cluster *and also* how poorly it fits into other clusters. This is a different way of looking at the same objective. Denote $a_{x_i}$ as the *average* distance from $x_i$ to all other points within its own cluster $k$. The lower the value, the better. On the other hand $b_{x_i}$ is the minimum average distance from $x_i$ to points in a different cluster, minimized over clusters. That is, compute separately for each cluster the average distance from $x_i$ to the points within that cluster, and then take the minimum. The silhouette $s(x_i)$ is defined as\n",
    "\n",
    "$$s(x_i) = \\frac{b_{x_i} - a_{x_i}}{\\max{\\left( a_{x_i}, b_{x_i}\\right)}}$$\n",
    "\n",
    "The silhouette score is computed on *every datapoint in every cluster*. The silhouette score ranges from -1 (a poor clustering) to +1 (a very dense clustering) with 0 denoting the situation where clusters overlap. Some criteria for the silhouette coefficient is provided in the table below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\n",
    "| Range       | Interpretation                                |\n",
    "|-------------|-----------------------------------------------|\n",
    "| 0.71 - 1.0  | A strong structure has been found.            |\n",
    "| 0.51 - 0.7  | A reasonable structure has been found.        |\n",
    "| 0.26 - 0.5  | The structure is weak and could be artificial.|\n",
    "| < 0.25      | No substantial structure has been found.      |\n",
    "\n",
    "</pre>\n",
    "Source: http://www.stat.berkeley.edu/~spector/s133/Clus.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, scikit-learn provides a function to compute this for us (phew!) called [`sklearn.metrics.silhouette_score`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html). Take a look at [this article](http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html) on picking $K$ in scikit-learn, as it will help you in the next exercise set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<h3>Checkup Exercise Set III</h3>\n",
    "\n",
    "<p><b>Exercise:</b> Using the documentation for the `silhouette_score` function above, construct a series of silhouette plots like the ones in the article linked above.</p>\n",
    "\n",
    "<p><b>Exercise:</b> Compute the average silhouette score for each $K$ and plot it. What $K$ does the plot suggest we should choose? Does it differ from what we found using the Elbow method?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.21909346385640693\n",
      "For n_clusters = 3 The average silhouette_score is : 0.2658897748623661\n",
      "For n_clusters = 4 The average silhouette_score is : 0.2842760972038074\n",
      "For n_clusters = 5 The average silhouette_score is : 0.2951643212287322\n",
      "For n_clusters = 6 The average silhouette_score is : 0.3201081495313936\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your turn.\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "figures = []\n",
    "X = x_cols\n",
    "range_n_clusters = [2, 3, 4, 5, 6]\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig = tools.make_subplots(rows=1, cols=2,\n",
    "                              print_grid=False,\n",
    "                              subplot_titles=('The silhouette plot for the various clusters.',\n",
    "                                              'The visualization of the clustered data.'))\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    fig['layout']['xaxis1'].update(title='The silhouette coefficient values',\n",
    "                                   range=[-0.1, 1])\n",
    "   \n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    fig['layout']['yaxis1'].update(title='Cluster label',\n",
    "                                   showticklabels=False,\n",
    "                                   range=[0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "    y_lower = 10\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        colors = matplotlib.colors.colorConverter.to_rgb(cm.Spectral(float(i) / n_clusters))\n",
    "        colors = 'rgb'+str(colors)\n",
    "      \n",
    "        filled_area = go.Scatter(y=np.arange(y_lower, y_upper),\n",
    "                                 x=ith_cluster_silhouette_values,\n",
    "                                 mode='lines',\n",
    "                                 showlegend=False,\n",
    "                                 line=dict(width=0.5,\n",
    "                                          color=colors))\n",
    "        fig.append_trace(filled_area, 1, 1)\n",
    "        \n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "        \n",
    "\n",
    "  \n",
    "    axis_line = go.Scatter(x=[silhouette_avg],\n",
    "                           y=[0, len(X) + (n_clusters + 1) * 10],\n",
    "                           showlegend=False,\n",
    "                           mode='lines',\n",
    "                           line=dict(color=\"red\", dash='dash',\n",
    "                                     width =1) )\n",
    "\n",
    "    fig.append_trace(axis_line, 1, 1)\n",
    "    \n",
    "    plt.scatter(x=[silhouette_avg],\n",
    "                           y= (n_clusters + 1))\n",
    "                           \n",
    "    colors = matplotlib.colors.colorConverter.to_rgb(cm.Spectral(float(i) / n_clusters))\n",
    "    colors = 'rgb'+str(colors)\n",
    "    clusters = go.Scatter(x=X[:, 0], \n",
    "                          y=X[:, 1], \n",
    "                          showlegend=False,\n",
    "                          mode='markers',\n",
    "                          marker=dict(color=colors,\n",
    "                                     size=4)\n",
    "                         )\n",
    "    fig.append_trace(clusters, 1, 2)\n",
    "    \n",
    "   \n",
    "    centers_ = clusterer.cluster_centers_\n",
    "   \n",
    "    centers = go.Scatter(x=centers_[:, 0], \n",
    "                         y=centers_[:, 1],\n",
    "                         showlegend=False,\n",
    "                         mode='markers',\n",
    "                         marker=dict(color='green', size=10,\n",
    "                                     line=dict(color='black',\n",
    "                                                             width=1))\n",
    "                        )\n",
    "\n",
    "    fig.append_trace(centers, 1, 2)\n",
    "    \n",
    "    fig['layout']['xaxis2'].update(title='Feature space for the 1st feature',\n",
    "                                   zeroline=False)\n",
    "    fig['layout']['yaxis2'].update(title='Feature space for the 2nd feature',\n",
    "                                  zeroline=False)\n",
    "                              \n",
    "\n",
    "    fig['layout'].update(title=\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                         \"with n_clusters = %d\" % n_clusters)\n",
    "    \n",
    "    figures.append(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing $K$: The Gap Statistic\n",
    "\n",
    "There is one last method worth covering for picking $K$, the so-called Gap statistic. The computation for the gap statistic builds on the sum-of-squares established in the Elbow method discussion, and compares it to the sum-of-squares of a \"null distribution,\" that is, a random set of points with no clustering. The estimate for the optimal number of clusters $K$ is the value for which $\\log{SS}$ falls the farthest below that of the reference distribution:\n",
    "\n",
    "$$G_k = E_n^*\\{\\log SS_k\\} - \\log SS_k$$\n",
    "\n",
    "In other words a good clustering yields a much larger difference between the reference distribution and the clustered data. The reference distribution is a Monte Carlo (randomization) procedure that constructs $B$ random distributions of points within the bounding box (limits) of the original data and then applies K-means to this synthetic distribution of data points.. $E_n^*\\{\\log SS_k\\}$ is just the average $SS_k$ over all $B$ replicates. We then compute the standard deviation $\\sigma_{SS}$ of the values of $SS_k$ computed from the $B$ replicates of the reference distribution and compute\n",
    "\n",
    "$$s_k = \\sqrt{1+1/B}\\sigma_{SS}$$\n",
    "\n",
    "Finally, we choose $K=k$ such that $G_k \\geq G_{k+1} - s_{k+1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: Choosing $K$ when we Have Labels\n",
    "\n",
    "Unsupervised learning expects that we do not have the labels. In some situations, we may wish to cluster data that is labeled. Computing the optimal number of clusters is much easier if we have access to labels. There are several methods available. We will not go into the math or details since it is rare to have access to the labels, but we provide the names and references of these measures.\n",
    "\n",
    "* Adjusted Rand Index\n",
    "* Mutual Information\n",
    "* V-Measure\n",
    "* Fowlkes–Mallows index\n",
    "\n",
    "See [this article](http://scikit-learn.org/stable/modules/clustering.html) for more information about these metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Clusters using PCA\n",
    "\n",
    "How do we visualize clusters? If we only had two features, we could likely plot the data as is. But we have 100 data points each containing 32 features (dimensions). Principal Component Analysis (PCA) will help us reduce the dimensionality of our data from 32 to something lower. For a visualization on the coordinate plane, we will use 2 dimensions. In this exercise, we're going to use it to transform our multi-dimensional dataset into a 2 dimensional dataset.\n",
    "\n",
    "This is only one use of PCA for dimension reduction. We can also use PCA when we want to perform regression but we have a set of highly correlated variables. PCA untangles these correlations into a smaller number of features/predictors all of which are orthogonal (not correlated). PCA is also used to reduce a large set of variables into a much smaller one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<h3>Checkup Exercise Set IV</h3>\n",
    "\n",
    "<p><b>Exercise:</b> Use PCA to plot your clusters:</p>\n",
    "\n",
    "<ul>\n",
    "<li> Use scikit-learn's [`PCA`](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) function to reduce the dimensionality of your clustering data to 2 components\n",
    "<li> Create a data frame with the following fields:\n",
    "  <ul>\n",
    "  <li> customer name\n",
    "  <li> cluster id the customer belongs to\n",
    "  <li> the two PCA components (label them `x` and `y`)\n",
    "  </ul>\n",
    "<li> Plot a scatterplot of the `x` vs `y` columns\n",
    "<li> Color-code points differently based on cluster ID\n",
    "<li> How do the clusters look? \n",
    "<li> Based on what you see, what seems to be the best value for $K$? Moreover, which method of choosing $K$ seems to have produced the optimal result visually?\n",
    "</ul>\n",
    "\n",
    "<p><b>Exercise:</b> Now look at both the original raw data about the offers and transactions and look at the fitted clusters. Tell a story about the clusters in context of the original data. For example, do the clusters correspond to wine variants or something else interesting?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your turn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we've done is we've taken those columns of 0/1 indicator variables, and we've transformed them into a 2-D dataset. We took one column and arbitrarily called it `x` and then called the other `y`. Now we can throw each point into a scatterplot. We color coded each point based on it's cluster so it's easier to see them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<h3>Exercise Set V</h3>\n",
    "\n",
    "<p>As we saw earlier, PCA has a lot of other uses. Since we wanted to visualize our data in 2 dimensions, restricted the number of dimensions to 2 in PCA. But what is the true optimal number of dimensions?</p>\n",
    "\n",
    "<p><b>Exercise:</b> Using a new PCA object shown in the next cell, plot the `explained_variance_` field and look for the elbow point, the point where the curve's rate of descent seems to slow sharply. This value is one possible value for the optimal number of dimensions. What is it?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your turn\n",
    "# Initialize a new PCA model with a default number of components.\n",
    "import sklearn.decomposition\n",
    "pca = sklearn.decomposition.PCA()\n",
    "pca.fit(X)\n",
    "\n",
    "# Do the rest on your own :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Clustering Algorithms\n",
    "\n",
    "k-means is only one of a ton of clustering algorithms. Below is a brief description of several clustering algorithms, and the table provides references to the other clustering algorithms in scikit-learn. \n",
    "\n",
    "* **Affinity Propagation** does not require the number of clusters $K$ to be known in advance! AP uses a \"message passing\" paradigm to cluster points based on their similarity. \n",
    "\n",
    "* **Spectral Clustering** uses the eigenvalues of a similarity matrix to reduce the dimensionality of the data before clustering in a lower dimensional space. This is tangentially similar to what we did to visualize k-means clusters using PCA. The number of clusters must be known a priori.\n",
    "\n",
    "* **Ward's Method** applies to hierarchical clustering. Hierarchical clustering algorithms take a set of data and successively divide the observations into more and more clusters at each layer of the hierarchy. Ward's method is used to determine when two clusters in the hierarchy should be combined into one. It is basically an extension of hierarchical clustering. Hierarchical clustering is *divisive*, that is, all observations are part of the same cluster at first, and at each successive iteration, the clusters are made smaller and smaller. With hierarchical clustering, a hierarchy is constructed, and there is not really the concept of \"number of clusters.\" The number of clusters simply determines how low or how high in the hierarchy we reference and can be determined empirically or by looking at the [dendogram](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.cluster.hierarchy.dendrogram.html).\n",
    "\n",
    "* **Agglomerative Clustering** is similar to hierarchical clustering but but is not divisive, it is *agglomerative*. That is, every observation is placed into its own cluster and at each iteration or level or the hierarchy, observations are merged into fewer and fewer clusters until convergence. Similar to hierarchical clustering, the constructed hierarchy contains all possible numbers of clusters and it is up to the analyst to pick the number by reviewing statistics or the dendogram.\n",
    "\n",
    "* **DBSCAN** is based on point density rather than distance. It groups together points with many nearby neighbors. DBSCAN is one of the most cited algorithms in the literature. It does not require knowing the number of clusters a priori, but does require specifying the neighborhood size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Algorithms in Scikit-learn\n",
    "<table border=\"1\">\n",
    "<colgroup>\n",
    "<col width=\"15%\" />\n",
    "<col width=\"16%\" />\n",
    "<col width=\"20%\" />\n",
    "<col width=\"27%\" />\n",
    "<col width=\"22%\" />\n",
    "</colgroup>\n",
    "<thead valign=\"bottom\">\n",
    "<tr><th>Method name</th>\n",
    "<th>Parameters</th>\n",
    "<th>Scalability</th>\n",
    "<th>Use Case</th>\n",
    "<th>Geometry (metric used)</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody valign=\"top\">\n",
    "<tr><td>K-Means</span></a></td>\n",
    "<td>number of clusters</td>\n",
    "<td>Very large<span class=\"pre\">n_samples</span>, medium <span class=\"pre\">n_clusters</span> with\n",
    "MiniBatch code</td>\n",
    "<td>General-purpose, even cluster size, flat geometry, not too many clusters</td>\n",
    "<td>Distances between points</td>\n",
    "</tr>\n",
    "<tr><td>Affinity propagation</td>\n",
    "<td>damping, sample preference</td>\n",
    "<td>Not scalable with n_samples</td>\n",
    "<td>Many clusters, uneven cluster size, non-flat geometry</td>\n",
    "<td>Graph distance (e.g. nearest-neighbor graph)</td>\n",
    "</tr>\n",
    "<tr><td>Mean-shift</td>\n",
    "<td>bandwidth</td>\n",
    "<td>Not scalable with <span class=\"pre\">n_samples</span></td>\n",
    "<td>Many clusters, uneven cluster size, non-flat geometry</td>\n",
    "<td>Distances between points</td>\n",
    "</tr>\n",
    "<tr><td>Spectral clustering</td>\n",
    "<td>number of clusters</td>\n",
    "<td>Medium <span class=\"pre\">n_samples</span>, small <span class=\"pre\">n_clusters</span></td>\n",
    "<td>Few clusters, even cluster size, non-flat geometry</td>\n",
    "<td>Graph distance (e.g. nearest-neighbor graph)</td>\n",
    "</tr>\n",
    "<tr><td>Ward hierarchical clustering</td>\n",
    "<td>number of clusters</td>\n",
    "<td>Large <span class=\"pre\">n_samples</span> and <span class=\"pre\">n_clusters</span></td>\n",
    "<td>Many clusters, possibly connectivity constraints</td>\n",
    "<td>Distances between points</td>\n",
    "</tr>\n",
    "<tr><td>Agglomerative clustering</td>\n",
    "<td>number of clusters, linkage type, distance</td>\n",
    "<td>Large <span class=\"pre\">n_samples</span> and <span class=\"pre\">n_clusters</span></td>\n",
    "<td>Many clusters, possibly connectivity constraints, non Euclidean\n",
    "distances</td>\n",
    "<td>Any pairwise distance</td>\n",
    "</tr>\n",
    "<tr><td>DBSCAN</td>\n",
    "<td>neighborhood size</td>\n",
    "<td>Very large <span class=\"pre\">n_samples</span>, medium <span class=\"pre\">n_clusters</span></td>\n",
    "<td>Non-flat geometry, uneven cluster sizes</td>\n",
    "<td>Distances between nearest points</td>\n",
    "</tr>\n",
    "<tr><td>Gaussian mixtures</td>\n",
    "<td>many</td>\n",
    "<td>Not scalable</td>\n",
    "<td>Flat geometry, good for density estimation</td>\n",
    "<td>Mahalanobis distances to  centers</td>\n",
    "</tr>\n",
    "<tr><td>Birch</td>\n",
    "<td>branching factor, threshold, optional global clusterer.</td>\n",
    "<td>Large <span class=\"pre\">n_clusters</span> and <span class=\"pre\">n_samples</span></td>\n",
    "<td>Large dataset, outlier removal, data reduction.</td>\n",
    "<td>Euclidean distance between points</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "Source: http://scikit-learn.org/stable/modules/clustering.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<h3>Exercise Set VI</h3>\n",
    "\n",
    "<p><b>Exercise:</b> Try clustering using the following algorithms. </p>\n",
    "<ol>\n",
    "<li>Affinity propagation\n",
    "<li>Spectral clustering\n",
    "<li>Agglomerative clustering\n",
    "<li>DBSCAN\n",
    "</ol>\n",
    "<p>How do their results compare? Which performs the best? Tell a story why you think it performs the best.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your turn"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
